{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c96a1-f71b-42a3-9e28-52887e936b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977a93a-f44d-435c-9a71-726fff0a3d48",
   "metadata": {},
   "source": [
    "# The function below is meant to be used with a json that is formatted like testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc83d63-1572-4fe5-9e31-e959fd00f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  DebertaV2Tokenizer, AutoModelForSequenceClassification\n",
    "def process_commits_and_generate_feedback_with_sciper(input_json_path, output_json_path, model_name_or_path, spacy_nlp_name=\"en_core_web_sm\", start=None, end=None):\n",
    "    \"\"\"\n",
    "    Processes commit messages grouped by sciper, generates grades and feedback, and calculates average grades.\n",
    "    Also calculates and prints total execution time, average time per SCIPER, and per commit.\n",
    "\n",
    "    Args:\n",
    "        input_json_path (str): Path to the input JSON file.\n",
    "        output_json_path (str): Path to save the output JSON file.\n",
    "        model_name_or_path (str): Hugging Face repo name or local path to model.\n",
    "        spacy_nlp_name (str, optional): The name of the Spacy model to be used.\n",
    "        start (int, optional): Start index for sciper processing.\n",
    "        end (int, optional): End index for sciper processing.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing sciper IDs, commits with grades, feedback, and average grades.\n",
    "    \"\"\"\n",
    "\n",
    "    commit_data = extract_commit_messages_per_sciper(input_json_path)\n",
    "\n",
    "    # Slice the sciper IDs if start and end are specified\n",
    "    sciper_ids = list(commit_data.keys())[start:end] if start is not None and end is not None else list(commit_data.keys())\n",
    "\n",
    "    output_data = {}\n",
    "\n",
    "    total_commits = 0\n",
    "    total_sciper_time = 0\n",
    "\n",
    "    # Load Spacy model\n",
    "    nlp = spacy.load(spacy_nlp_name)\n",
    "\n",
    "    # Load tokenizer and model from HF or local\n",
    "    tokenizer = DebertaV2Tokenizer.from_pretrained(model_name_or_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path)\n",
    "    \n",
    "    # # Use this piece of code instead of the previous one to use the classic BERT\n",
    "    # tokenizer = BertTokenizer.from_pretrained(model_path_or_name)\n",
    "    # model = BertForSequenceClassification.from_pretrained(model_path_or_name)\n",
    "\n",
    "\n",
    "    # Start timing\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    for sciper in tqdm(sciper_ids, desc=\"Processing SCIPERs\"):\n",
    "        sciper_start_time = time.time()\n",
    "        \n",
    "        commits = commit_data[sciper]\n",
    "        total_grade = 0\n",
    "        processed_commits = []\n",
    "\n",
    "        for idx, commit in enumerate(tqdm(commits, desc=f\"Processing commits for SCIPER {sciper}\", leave=False), start=1):\n",
    "            commit_message = commit[\"commit_message\"]\n",
    "            commit_hash = commit[\"hash\"]\n",
    "\n",
    "            print(f\"Grading commit {idx} of {len(commits)} for SCIPER {sciper}\")\n",
    "\n",
    "            grade_results = grade_commit_message(commit_message, nlp, tokenizer, model, no_openai=False)\n",
    "            description_grade = grade_results[0]\n",
    "            final_grade = grade_results[1]\n",
    "            errors = {\n",
    "                \"is_desc_too_long\": grade_results[2],\n",
    "                \"is_uppercase\": grade_results[3],\n",
    "                \"is_not_imp_verb\": grade_results[4],\n",
    "                \"is_perfect_prefix\": grade_results[5],\n",
    "                \"is_uppercase_prefix\": grade_results[6],\n",
    "                \"is_typo_prefix\": grade_results[7],\n",
    "                \"is_uppercase_and_typo_prefix\": grade_results[8],\n",
    "                \"is_invalid_prefix\": grade_results[9],\n",
    "                \"is_body_meaningful\": grade_results[10],\n",
    "                \"is_body_too_long\": grade_results[11],\n",
    "                \"is_body_evaluated\": grade_results[12],\n",
    "            }\n",
    "\n",
    "            feedback = generate_feedback(commit_message, final_grade, description_grade, errors)\n",
    "\n",
    "            processed_commits.append({\n",
    "                \"hash\": commit_hash,\n",
    "                \"commit_message\": commit_message,\n",
    "                \"grade\": final_grade,\n",
    "                \"feedback\": feedback\n",
    "            })\n",
    "\n",
    "            total_grade += final_grade\n",
    "            total_commits += 1\n",
    "\n",
    "        average_grade = round(total_grade / len(commits), 2) if commits else 0\n",
    "\n",
    "        output_data[sciper] = {\n",
    "            \"commits\": processed_commits,\n",
    "            \"average_grade\": average_grade\n",
    "        }\n",
    "\n",
    "        sciper_time = time.time() - sciper_start_time\n",
    "        total_sciper_time += sciper_time\n",
    "\n",
    "    total_end_time = time.time()\n",
    "    total_duration = total_end_time - total_start_time\n",
    "\n",
    "    average_time_per_sciper = total_sciper_time / len(sciper_ids) if sciper_ids else 0\n",
    "    average_time_per_commit = total_duration / total_commits if total_commits else 0\n",
    "\n",
    "    with open(output_json_path, \"w\") as file:\n",
    "        json.dump(output_data, file, indent=4)\n",
    "\n",
    "    print(\"\\n--- Time Statistics ---\")\n",
    "    print(f\"Total time: {total_duration:.2f} seconds\")\n",
    "    print(f\"Average time per SCIPER: {average_time_per_sciper:.2f} seconds\")\n",
    "    print(f\"Average time per commit: {average_time_per_commit:.2f} seconds\")\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    print(\"Processing complete. Results saved to:\", output_json_path)\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb4a840-6ca1-4093-a8e9-a78bf8ca59ff",
   "metadata": {},
   "source": [
    "# This is an example usage (run it to grade the testing_data (B3 grades))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ee009e-9401-4049-8d25-899ce587e200",
   "metadata": {},
   "source": [
    "## **!!! Please keep in mind that this is linked to a personal OpenAI API key, and each run debits money to generate feedback, so use it responsibly when testing) !!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9023d7da-aeeb-4173-9be1-bc7b0e995ae6",
   "metadata": {},
   "source": [
    "### use the *start* and *end* args to grade a limited number of commit messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255afba2-2e28-423f-82c1-2ecaa6df4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_json_path = \"testing_data.json\"\n",
    "output_json_path = \"output_grading_compare_deberta_5_7.json\"\n",
    "\n",
    "# Use Hugging Face repo name instead of local folder\n",
    "model_name_or_path = \"albertfares/CommitGraderModelDeBERTa\"\n",
    "\n",
    "# Set your API key here\n",
    "# openai.api_key = \"\"\n",
    "\n",
    "# Process a subset of SCIPERs (from start incl. to end excl.)\n",
    "results = process_commits_and_generate_feedback_with_sciper(\n",
    "    input_json_path, \n",
    "    output_json_path, \n",
    "    model_name_or_path, \n",
    "    start=5, \n",
    "    end=7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469a737d-9944-4107-88f8-294e105aa52d",
   "metadata": {},
   "source": [
    "# The function below is used to grade a single commit message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a753c-2e0f-4b27-98c2-84262ff0db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  DebertaV2Tokenizer, AutoModelForSequenceClassification\n",
    "def process_single_commit(commit_message, model_path, spacy_nlp_name=\"en_core_web_sm\"):\n",
    "    \"\"\"\n",
    "    Processes a single commit message, grades it, and generates feedback.\n",
    "\n",
    "    Args:\n",
    "        commit_message (str): The commit message to process.\n",
    "        model_path (str): The path to the trained BERT model to be used\n",
    "        spacy_nlp_name (str, optional): The name of the Spacy model to be used\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the commit message, grade, and feedback.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        # Load the chosen spacy model\n",
    "        nlp = spacy.load(spacy_nlp_name)\n",
    "        \n",
    "        # Load the trained BERT model using the model's path\n",
    "        tokenizer = DebertaV2Tokenizer.from_pretrained(model_path)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        \n",
    "        # Run grading logic\n",
    "        grade_results = grade_commit_message(commit_message, nlp, tokenizer, model, no_openai=False)\n",
    "        description_grade = grade_results[0]\n",
    "        final_grade = grade_results[1]\n",
    "        errors = {\n",
    "            \"is_desc_too_long\": grade_results[2],\n",
    "            \"is_uppercase\": grade_results[3],\n",
    "            \"is_not_imp_verb\": grade_results[4],\n",
    "            \"is_perfect_prefix\": grade_results[5],\n",
    "            \"is_uppercase_prefix\": grade_results[6],\n",
    "            \"is_typo_prefix\": grade_results[7],\n",
    "            \"is_uppercase_and_typo_prefix\": grade_results[8],\n",
    "            \"is_invalid_prefix\": grade_results[9],\n",
    "            \"is_body_meaningful\": grade_results[10],\n",
    "            \"is_body_too_long\": grade_results[11],\n",
    "            \"is_body_evaluated\": grade_results[12],\n",
    "        }\n",
    "\n",
    "        # Generate feedback\n",
    "        feedback = generate_feedback(commit_message, final_grade, description_grade, errors)\n",
    "\n",
    "        # Create result dictionary\n",
    "        result = {\n",
    "            \"commit_message\": commit_message,\n",
    "            \"grade\": final_grade,\n",
    "            \"feedback\": feedback\n",
    "        }\n",
    "\n",
    "        # Print results\n",
    "        print(f\"Commit Message: {commit_message}\")\n",
    "        print(f\"Grade: {final_grade}\")\n",
    "        print(f\"Feedback: {feedback}\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc792dc-1f1e-4db3-904b-936b803bb20e",
   "metadata": {},
   "source": [
    "### This is an example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9963ec3d-71f2-4f5d-9cf9-31bd1a267db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"albertfares/CommitGraderModelDeBERTa\"\n",
    "\n",
    "# openai.api_key = \"\"\n",
    "\n",
    "commit_message = \"format: runnning ktfmt\"\n",
    "\n",
    "\n",
    "result = process_single_commit(commit_message, model_name_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d3e85c",
   "metadata": {},
   "source": [
    "### Old BERT version below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df2087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_commit2(commit_message, model_path, spacy_nlp_name=\"en_core_web_sm\"):\n",
    "    \"\"\"\n",
    "    Processes a single commit message, grades it, and generates feedback.\n",
    "\n",
    "    Args:\n",
    "        commit_message (str): The commit message to process.\n",
    "        model_path (str): The path to the trained BERT model to be used\n",
    "        spacy_nlp_name (str, optional): The name of the Spacy model to be used\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the commit message, grade, and feedback.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        # Load the chosen spacy model\n",
    "        nlp = spacy.load(spacy_nlp_name)\n",
    "        \n",
    "        # Load the trained BERT model using the model's path\n",
    "        tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "        model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "        \n",
    "        # Run grading logic\n",
    "        grade_results = grade_commit_message(commit_message, nlp, tokenizer, model, no_openai=False)\n",
    "        description_grade = grade_results[0]\n",
    "        final_grade = grade_results[1]\n",
    "        errors = {\n",
    "            \"is_desc_too_long\": grade_results[2],\n",
    "            \"is_uppercase\": grade_results[3],\n",
    "            \"is_not_imp_verb\": grade_results[4],\n",
    "            \"is_perfect_prefix\": grade_results[5],\n",
    "            \"is_uppercase_prefix\": grade_results[6],\n",
    "            \"is_typo_prefix\": grade_results[7],\n",
    "            \"is_uppercase_and_typo_prefix\": grade_results[8],\n",
    "            \"is_invalid_prefix\": grade_results[9],\n",
    "            \"is_body_meaningful\": grade_results[10],\n",
    "            \"is_body_too_long\": grade_results[11],\n",
    "            \"is_body_evaluated\": grade_results[12],\n",
    "        }\n",
    "\n",
    "        # Generate feedback\n",
    "        feedback = generate_feedback(commit_message, final_grade, description_grade, errors)\n",
    "\n",
    "        # Create result dictionary\n",
    "        result = {\n",
    "            \"commit_message\": commit_message,\n",
    "            \"grade\": final_grade,\n",
    "            \"feedback\": feedback\n",
    "        }\n",
    "\n",
    "        # Print results\n",
    "        print(f\"Commit Message: {commit_message}\")\n",
    "        print(f\"Grade: {final_grade}\")\n",
    "        print(f\"Feedback: {feedback}\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f053de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"albertfares/CommitGraderModel\"\n",
    "\n",
    "# openai.api_key = \"\"\n",
    "\n",
    "commit_message = \"test(map): add ui tests for map\"\n",
    "\n",
    "\n",
    "result = process_single_commit2(commit_message, model_name_or_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
